{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lusiadas/lusiadas.txt', 'r', encoding='ISO-8859-1') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in char:  318182\n"
     ]
    }
   ],
   "source": [
    "print('Length of dataset in char: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "As armas e os barões assinalados,\n",
      "Que da ocidental praia Lusitana,\n",
      "Por mares nunca de antes navegados,\n",
      "Passaram ainda além da Taprobana,\n",
      "Em perigos e guerras esforçados,\n",
      "Mais do que prometia a força humana,\n",
      "E entre gente remota edificaram\n",
      "Novo Reino, que tanto sublimaram;\n",
      "\n",
      "2\n",
      "E também as memórias gloriosas\n",
      "Daqueles Reis, que foram dilatando\n",
      "A Fé, o Império, e as terras viciosas\n",
      "De África e de Ásia andaram devastando;\n",
      "E aqueles, que por obras valerosas\n",
      "Se vão da lei da morte libertando;\n",
      "Cantando espalharei por toda parte,\n",
      "Se a tanto me ajudar o engenho e arte.\n",
      "\n",
      "3\n",
      "Cessem do sábio Grego e do Troiano\n",
      "As navegações grandes que fizeram;\n",
      "Cale-se de Alexandro e de Trajano\n",
      "A fama das vitórias que tiveram;\n",
      "Que eu canto o peito ilustre Lusitano,\n",
      "A quem Neptuno e Marte obedeceram:\n",
      "Cesse tudo o que a Musa antígua canta,\n",
      "Que outro valor mais alto se alevanta.\n",
      "\n",
      "4\n",
      "E vós, Tágides minhas, pois criado\n",
      "Tendes em mim um novo engenho ardente,\n",
      "Se sempre em verso humilde celebrado\n",
      "Foi de mim vosso rio alegre\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.0123456789:;?ABCDEFGHIJLMNOPQRSTUVXZ[]abcdefghijlmnopqrstuvxyzÀÁÉÍÓÔÚàáâãçèéêíòóôõúü\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_str = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [str_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_str[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65, 80, 49, 56, 61, 1, 29, 64, 52, 54, 61]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('sábio Grego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sábio Grego'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([65, 80, 49, 56, 61, 1, 29, 64, 52, 54, 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([318182]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11,  0, 23, 65,  1, 48, 64, 59, 48, 65,  1, 52,  1, 61, 65,  1, 49, 48,\n",
      "        64, 91, 52, 65,  1, 48, 65, 65, 56, 60, 48, 58, 48, 51, 61, 65,  7,  0,\n",
      "        38, 67, 52,  1, 51, 48,  1, 61, 50, 56, 51, 52, 60, 66, 48, 58,  1, 62,\n",
      "        64, 48, 56, 48,  1, 33, 67, 65, 56, 66, 48, 60, 48,  7,  0, 37, 61, 64,\n",
      "         1, 59, 48, 64, 52, 65,  1, 60, 67, 60, 50, 48,  1, 51, 52,  1, 48, 60,\n",
      "        66, 52, 65,  1, 60, 48, 68, 52, 54, 48, 51, 61, 65,  7,  0, 37, 48, 65,\n",
      "        65, 48, 64, 48, 59,  1, 48, 56, 60, 51, 48,  1, 48, 58, 85, 59,  1, 51,\n",
      "        48,  1, 41, 48, 62, 64, 61, 49, 48, 60, 48,  7,  0, 27, 59,  1, 62, 52,\n",
      "        64, 56, 54, 61, 65,  1, 52,  1, 54, 67, 52, 64, 64, 48, 65,  1, 52, 65,\n",
      "        53, 61, 64, 83, 48, 51, 61, 65,  7,  0, 34, 48, 56, 65,  1, 51, 61,  1,\n",
      "        63, 67, 52,  1, 62, 64, 61, 59, 52, 66, 56, 48,  1, 48,  1, 53, 61, 64,\n",
      "        83, 48,  1, 55, 67, 59, 48, 60, 48,  7,  0, 27,  1, 52, 60, 66, 64, 52,\n",
      "         1, 54, 52, 60, 66, 52,  1, 64, 52, 59, 61, 66, 48,  1, 52, 51, 56, 53,\n",
      "        56, 50, 48, 64, 48, 59,  0, 35, 61, 68, 61,  1, 39, 52, 56, 60, 61,  7,\n",
      "         1, 63, 67, 52,  1, 66, 48, 60, 66, 61,  1, 65, 67, 49, 58, 56, 59, 48,\n",
      "        64, 48, 59, 21,  0,  0, 12,  0, 27,  1, 66, 48, 59, 49, 85, 59,  1, 48,\n",
      "        65,  1, 59, 52, 59, 89, 64, 56, 48, 65,  1, 54, 58, 61, 64, 56, 61, 65,\n",
      "        48, 65,  0, 26, 48, 63, 67, 52, 58, 52, 65,  1, 39, 52, 56, 65,  7,  1,\n",
      "        63, 67, 52,  1, 53, 61, 64, 48, 59,  1, 51, 56, 58, 48, 66, 48, 60, 51,\n",
      "        61,  0, 23,  1, 28, 85,  7,  1, 61,  1, 31, 59, 62, 85, 64, 56, 61,  7,\n",
      "         1, 52,  1, 48, 65,  1, 66, 52, 64, 64, 48, 65,  1, 68, 56, 50, 56, 61,\n",
      "        65, 48, 65,  0, 26, 52,  1, 73, 53, 64, 56, 50, 48,  1, 52,  1, 51, 52,\n",
      "         1, 73, 65, 56, 48,  1, 48, 60, 51, 48, 64, 48, 59,  1, 51, 52, 68, 48,\n",
      "        65, 66, 48, 60, 51, 61, 21,  0, 27,  1, 48, 63, 67, 52, 58, 52, 65,  7,\n",
      "         1, 63, 67, 52,  1, 62, 61, 64,  1, 61, 49, 64, 48, 65,  1, 68, 48, 58,\n",
      "        52, 64, 61, 65, 48, 65,  0, 40, 52,  1, 68, 82, 61,  1, 51, 48,  1, 58,\n",
      "        52, 56,  1, 51, 48,  1, 59, 61, 64, 66, 52,  1, 58, 56, 49, 52, 64, 66,\n",
      "        48, 60, 51, 61, 21,  0, 25, 48, 60, 66, 48, 60, 51, 61,  1, 52, 65, 62,\n",
      "        48, 58, 55, 48, 64, 52, 56,  1, 62, 61, 64,  1, 66, 61, 51, 48,  1, 62,\n",
      "        48, 64, 66, 52,  7,  0, 40, 52,  1, 48,  1, 66, 48, 60, 66, 61,  1, 59,\n",
      "        52,  1, 48, 57, 67, 51, 48, 64,  1, 61,  1, 52, 60, 54, 52, 60, 55, 61,\n",
      "         1, 52,  1, 48, 64, 66, 52,  9,  0,  0, 13,  0, 25, 52, 65, 65, 52, 59,\n",
      "         1, 51, 61,  1, 65, 80, 49, 56, 61,  1, 29, 64, 52, 54, 61,  1, 52,  1,\n",
      "        51, 61,  1, 41, 64, 61, 56, 48, 60, 61,  0, 23, 65,  1, 60, 48, 68, 52,\n",
      "        54, 48, 83, 91, 52, 65,  1, 54, 64, 48, 60, 51, 52, 65,  1, 63, 67, 52,\n",
      "         1, 53, 56, 71, 52, 64, 48, 59, 21,  0, 25, 48, 58, 52,  8, 65, 52,  1,\n",
      "        51, 52,  1, 23, 58, 52, 69, 48, 60, 51, 64, 61,  1, 52,  1, 51, 52,  1,\n",
      "        41, 64, 48, 57, 48, 60, 61,  0, 23,  1, 53, 48, 59, 48,  1, 51, 48, 65,\n",
      "         1, 68, 56, 66, 89, 64, 56, 48, 65,  1, 63, 67, 52,  1, 66, 56, 68, 52,\n",
      "        64, 48, 59, 21,  0, 38, 67, 52,  1, 52, 67,  1, 50, 48, 60, 66, 61,  1,\n",
      "        61,  1, 62, 52, 56, 66, 61,  1, 56, 58, 67, 65, 66, 64, 52,  1, 33, 67,\n",
      "        65, 56, 66, 48, 60, 61,  7,  0, 23,  1, 63, 67, 52, 59,  1, 35, 52, 62,\n",
      "        66, 67, 60, 61,  1, 52,  1, 34, 48, 64, 66, 52,  1, 61, 49, 52, 51, 52,\n",
      "        50, 52, 64, 48, 59, 20,  0, 25, 52, 65, 65, 52,  1, 66, 67, 51, 61,  1,\n",
      "        61,  1, 63, 67, 52,  1, 48,  1, 34, 67, 65, 48,  1, 48, 60, 66, 87, 54,\n",
      "        67, 48,  1, 50, 48, 60, 66, 48,  7,  0, 38, 67, 52,  1, 61, 67, 66, 64,\n",
      "        61,  1, 68, 48, 58, 61, 64,  1, 59, 48, 56, 65,  1, 48, 58, 66, 61,  1,\n",
      "        65, 52,  1, 48, 58, 52, 68, 48, 60, 66, 48,  9,  0,  0, 14,  0, 27,  1,\n",
      "        68, 89, 65,  7,  1, 41, 80, 54, 56, 51, 52, 65,  1, 59, 56, 60, 55, 48,\n",
      "        65,  7,  1, 62, 61, 56, 65,  1, 50, 64, 56, 48, 51, 61,  0, 41, 52, 60,\n",
      "        51, 52, 65,  1, 52, 59,  1, 59, 56, 59,  1, 67, 59,  1, 60, 61, 68, 61,\n",
      "         1, 52, 60, 54, 52, 60, 55, 61,  1, 48, 64, 51, 52, 60, 66, 52,  7,  0,\n",
      "        40, 52,  1, 65, 52, 59, 62, 64, 52,  1, 52, 59,  1, 68, 52, 64, 65, 61,\n",
      "         1, 55, 67, 59, 56, 58, 51, 52,  1, 50, 52, 58, 52, 49, 64, 48, 51, 61,\n",
      "         0, 28, 61, 56,  1, 51, 52,  1, 59, 56, 59,  1, 68, 61, 65, 65, 61,  1,\n",
      "        64, 56, 61,  1, 48, 58, 52, 54, 64, 52])\n"
     ]
    }
   ],
   "source": [
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.9*len(data))\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  0, 23, 65,  1, 48, 64, 59, 48])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_size = 8\n",
    "train_data[:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([11])\n",
      "target: 0\n",
      "context: tensor([11,  0])\n",
      "target: 23\n",
      "context: tensor([11,  0, 23])\n",
      "target: 65\n",
      "context: tensor([11,  0, 23, 65])\n",
      "target: 1\n",
      "context: tensor([11,  0, 23, 65,  1])\n",
      "target: 48\n",
      "context: tensor([11,  0, 23, 65,  1, 48])\n",
      "target: 64\n",
      "context: tensor([11,  0, 23, 65,  1, 48, 64])\n",
      "target: 59\n",
      "context: tensor([11,  0, 23, 65,  1, 48, 64, 59])\n",
      "target: 48\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_size]\n",
    "y = train_data[1:context_size+1]\n",
    "\n",
    "for t in range(context_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'context: {context}\\ntarget: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4, 8])\n",
      "tensor([[49, 64, 48, 60, 50, 48, 65, 21],\n",
      "        [48,  1, 54, 52, 60, 66, 52,  0],\n",
      "        [66, 52, 60, 51, 52, 64, 48, 59],\n",
      "        [51, 61,  7,  0, 27,  1, 51, 52]])\n",
      "targets: torch.Size([4, 8])\n",
      "tensor([[64, 48, 60, 50, 48, 65, 21,  0],\n",
      "        [ 1, 54, 52, 60, 66, 52,  0, 30],\n",
      "        [52, 60, 51, 52, 64, 48, 59, 21],\n",
      "        [61,  7,  0, 27,  1, 51, 52, 62]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4\n",
    "context_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    index = torch.randint(len(data)- context_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_size] for i in index])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in index])\n",
    "    return x,y\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "print(f'inputs: {xb.shape}\\n{xb}')\n",
    "print(f'targets: {yb.shape}\\n{yb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([49])\n",
      "target:64\n",
      "input: tensor([49, 64])\n",
      "target:48\n",
      "input: tensor([49, 64, 48])\n",
      "target:60\n",
      "input: tensor([49, 64, 48, 60])\n",
      "target:50\n",
      "input: tensor([49, 64, 48, 60, 50])\n",
      "target:48\n",
      "input: tensor([49, 64, 48, 60, 50, 48])\n",
      "target:65\n",
      "input: tensor([49, 64, 48, 60, 50, 48, 65])\n",
      "target:21\n",
      "input: tensor([49, 64, 48, 60, 50, 48, 65, 21])\n",
      "target:0\n",
      "input: tensor([48])\n",
      "target:1\n",
      "input: tensor([48,  1])\n",
      "target:54\n",
      "input: tensor([48,  1, 54])\n",
      "target:52\n",
      "input: tensor([48,  1, 54, 52])\n",
      "target:60\n",
      "input: tensor([48,  1, 54, 52, 60])\n",
      "target:66\n",
      "input: tensor([48,  1, 54, 52, 60, 66])\n",
      "target:52\n",
      "input: tensor([48,  1, 54, 52, 60, 66, 52])\n",
      "target:0\n",
      "input: tensor([48,  1, 54, 52, 60, 66, 52,  0])\n",
      "target:30\n",
      "input: tensor([66])\n",
      "target:52\n",
      "input: tensor([66, 52])\n",
      "target:60\n",
      "input: tensor([66, 52, 60])\n",
      "target:51\n",
      "input: tensor([66, 52, 60, 51])\n",
      "target:52\n",
      "input: tensor([66, 52, 60, 51, 52])\n",
      "target:64\n",
      "input: tensor([66, 52, 60, 51, 52, 64])\n",
      "target:48\n",
      "input: tensor([66, 52, 60, 51, 52, 64, 48])\n",
      "target:59\n",
      "input: tensor([66, 52, 60, 51, 52, 64, 48, 59])\n",
      "target:21\n",
      "input: tensor([51])\n",
      "target:61\n",
      "input: tensor([51, 61])\n",
      "target:7\n",
      "input: tensor([51, 61,  7])\n",
      "target:0\n",
      "input: tensor([51, 61,  7,  0])\n",
      "target:27\n",
      "input: tensor([51, 61,  7,  0, 27])\n",
      "target:1\n",
      "input: tensor([51, 61,  7,  0, 27,  1])\n",
      "target:51\n",
      "input: tensor([51, 61,  7,  0, 27,  1, 51])\n",
      "target:52\n",
      "input: tensor([51, 61,  7,  0, 27,  1, 51, 52])\n",
      "target:62\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(context_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'input: {context}\\ntarget:{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 94])\n",
      "tensor(4.8162, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets= targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 94])\n",
      "tensor(4.8162, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
